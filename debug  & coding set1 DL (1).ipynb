{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb730978-5d19-4877-a5a4-57d7c1f8e676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#!pip install scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "#!pip install pandas\n",
    "\n",
    "# Generate dummy dataset\n",
    "data = pd.DataFrame({\n",
    "    'Feature1': np.random.rand(100),\n",
    "    'Feature2': np.random.rand(100),\n",
    "    'Label': np.random.randint(0, 2, size=100)\n",
    "})\n",
    "\n",
    "# Split dataset\n",
    "X = data[['Feature1', 'Feature2']]\n",
    "y = data['Label']\n",
    "\n",
    "# Scaling features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build ANN Model\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(3,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "eval_loss, eval_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {eval_accuracy}\")\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(X_test)\n",
    "predicted_classes = (predictions > 0.5).astype(int)\n",
    "print(predicted_classes[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ad2d7-a766-4f67-8951-b8ee531479a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64733d-ac01-45a7-bbe3-4f681842f86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8138d5-e657-46d8-bdf6-6b18c349d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b1dfdf0-25b3-49b2-99ea-4f98551d6ad2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af4886-12fb-4ccc-9cf1-5ed01dc1688d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image Preprocessing for inference (PyTorch)\n",
    "# write a function to load an image and preprocess it for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be81cc9-b1db-4f97-9ea4-d35d1640311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adce5b-5c46-42eb-ba43-de48ad4aa9be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f61d6-ad1e-436e-ad3a-4ad290603067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(image_path):\n",
    "    preprocess = transform.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                   ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0) \n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c1580-0b41-49a6-8ba5-5f618a5ae762",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = load_and_preprocess(\"test_image.jpg\")\n",
    "print(input_tensor_shape)   #torch.size([1, 3, 224, 224])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67a0a00-6812-44b5-9eaa-38e9823ffb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfcaf72-a4e4-42a4-b6d4-08a0ecd5a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2: Predict on New Image with a Trained Model\n",
    "#Problem: Perform prediction and get the class label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f964b0-59ab-4124-8111-2381e0a6cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "def load_and_preprocess(image_path):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.435, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    image = Image.open(image_path)\n",
    "    input_tensor = preprocess(image)\n",
    "    input_tensor = input_tensor.unsqueeze(0)\n",
    "    return input_tensor\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae74f07-62c5-4dc3-ac93-5849a15b10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    _, predictd_idx = torch.max(output, 1)\n",
    "    class_label = class_labels[predicted_idx]\n",
    "    print(class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e10a3b3-2c13-4b19-9918-443a9eae162a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3: Build a CNN to classify CIFAR-10 images (PyTorch)\n",
    "#Problem: Create a CNN model that classifies images from the CIFAR-10 dataset with accuracy above 60%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84541687-531c-4c8a-b9b0-ab43be3d7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class CIFAR10CNN(nn.Module):\n",
    "    def__init__(self):\n",
    "    \n",
    "       super(CIFAR10CNN, self).__init__()\n",
    "       self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "       self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "       self.pool = nn.MakPool2d(2, 2)\n",
    "       self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "       self.fc2 = nn.Linear(512, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conV1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "model = CIFAR10CNN()\n",
    "model.eval()\n",
    "input_tensor = torch.randn(1, 3, 32, 32)\n",
    "with torch.no_grand():\n",
    "    output = model(input_tensor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070b9dab-b10c-4e1a-ae9f-845421cd0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4: Identify Overfitting from Training Logs and Solve It\n",
    "#Problem: You notice the training accuracy increases but validation accuracy stagnates. Modify the model using dropout and early stopping. (use mnist dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec1a7b-66d4-47d8-9557-6c4d8c5517bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "def load_and_preprocess_image(image_path):\n",
    "    image = Image.open(image_path),convert((\"RGB\")\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = preprocess(image).unsqueeze(0)\n",
    "    return input_tensor\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e3890-94f4-4b48-8f58-77b6d9d0079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "\n",
    "base_model = VGG16(include_top=False, input_shape=(224, 224, 3), weights='imagenet')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1190e49-a312-4774-8776-419ba88dfd99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
